---
title: "Employee Turnover Prediction"
author: "Albesa Istrefaj, Antonia Durisch, Philipp Drebes"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# MSCIDS MPM02: Employee Turnover Prediction

## Introduction

Welcome to our project on employee turnover prediction! In this project, we will be using various machine learning algorithms to analyze a dataset containing employee turnover data and develop predictive models.

Employee turnover is a critical issue for companies, as it can result in significant costs such as recruitment, training, and lost productivity. Identifying factors that contribute to employee turnover and developing accurate predictive models can help companies better understand employee behavior and improve employee retention.

TODO\
Check if response var is balanced\
preProcess

## Preparation and Exploration

Load the libraries.

```{r}
library(vioplot)
library(caret)
library(vtreat)
library(ggcorrplot)
library(readr)
library(ggplot2)
library(gridExtra)
library(mgcv)
```

Load and inspect the data.

```{r}
turnover <- read_csv('data/turnover.csv', col_names=TRUE)
summary(turnover)

# Having a look at the structure.
str(HRdata)
```

## Exploration

```{r}
# scatterplot of stag vs. extraversion
ggplot(data = HRdata, aes(x = stag, y = extraversion)) +
  geom_point()

# visualizing the distribution of a categorical variable - distribution of industry
ggplot(data = HRdata, aes(x = industry)) +
  geom_bar()

# distribution of a continuous variable - box plot of age by gender
ggplot(data = HRdata, aes(x = gender, y = age)) +
  geom_boxplot()

# histogram of the age
hist(HRdata$age)

# boxplot of the age
boxplot(HRdata$age)

# plot of age and extraversion
plot(HRdata$age, HRdata$extraversion)

# barplot of gender - male and female
barplot(table(HRdata$gender))

# density plots
plot(density(HRdata$age))

# violin plot
vioplot(HRdata$age)
```

### One-Hot encoding

```{r}
dummy <- dummyVars(" ~ .", data=df)

#perform one-hot encoding on data frame
turnover.oh <- data.frame(predict(dummy, newdata=df))

#summary(turnover.oh)
```

## Linear Models

### Naive Approach

In this chapter, we will be exploring Regression, which is a type of machine learning algorithm used for predicting numerical values. We will explain how regression works, how to train a regression model, and how to use it to predict the likelihood of an employee leaving the company.

```{r}
correlationMatrix <- cor(turnover.oh)
ggcorrplot(correlationMatrix, hc.order = TRUE)

# find attributes that are highly corrected ( > 0.75 )
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
highlyCorrelated <- sort(highlyCorrelated)

# print indexes of highly correlated attributes
print(highlyCorrelated)
names(turnover.oh[highlyCorrelated])

turnover.reduced = turnover.oh[,-c(highlyCorrelated)]

ggcorrplot(cor(turnover.reduced), hc.order = TRUE)
```

```{r}
fit <- lm(event ~ ., data = turnover.reduced)
summary(fit)
```

#### Interpretation

It appears that this model has not a good fit...

### Non-linearities

First we inspect all numerical coefficients for non-linearities.

```{r}

## Age
gg.age <- ggplot(data = turnover, mapping = aes(y = event, x = age)) + 
  geom_point()

plot.age <- gg.age + geom_smooth()

## Extraversion
gg.extraversion <- ggplot(data = turnover, mapping = aes(y = event, x = extraversion)) + 
  geom_point()

plot.extraversion <- gg.extraversion +  geom_smooth()

## Independence
gg.independence <- ggplot(data = turnover, mapping = aes(y = event, x = independ)) + 
  geom_point()

plot.independence <- gg.independence + geom_smooth()

## Self-control
gg.selfcontrol <- ggplot(data = turnover, mapping = aes(y = event, x = selfcontrol)) + 
  geom_point()

plot.selfcontrol <- gg.selfcontrol + geom_smooth()

## Anxiety
gg.anxiety <- ggplot(data = turnover, mapping = aes(y = event, x = anxiety)) + 
  geom_point()

plot.anxiety <- gg.anxiety + geom_smooth()

## Innovator
gg.innovator <- ggplot(data = turnover, mapping = aes(y = event, x = novator)) + 
  geom_point()

plot.innovator <- gg.innovator + geom_smooth()

grid.arrange(plot.age, plot.extraversion, gg.independence, plot.selfcontrol, plot.anxiety, plot.innovator, ncol=2)
```

It appears that only the factor age has a non-linear behavior. We will use a GAM to find its complexity.

```{r}
gam.turnover.1 <- gam(event ~ traffic + way + s(age), 
                      data = turnover, family = binomial)
summary(gam.turnover.1)

plot(gam.turnover.1, residuals = TRUE, select = 1)
```

### Feature Selection

```{r}
# ensure results are repeatable
set.seed(7)
# load the library
library(mlbench)
library(caret)
library(arm)

# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(event~., data=turnover.reduced, method="glm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)

# summarize importance
print(importance)
# plot importance
plot(importance)

summary(model)
```

### GLM

```{r}
glm.turnover <- glm(event ~ traffic + way + age + profession, 
                    data = turnover, family = binomial)
summary(glm.turnover)

plot(glm.turnover)
```

## Support Vector Machines

In this chapter, we will be exploring the Support Vector Machines (SVM) algorithm. SVM is a powerful algorithm for classification and regression, and is commonly used in machine learning. We will explain how SVM works, how to train an SVM model, and how to use it to predict employee turnover.

```{r}
# Split the data into training and testing sets
set.seed(123)
train_index <- createDataPartition(dummy_data[, "event"], p = 0.7, list = FALSE)
train_data <- dummy_data[train_index, ]
test_data <- dummy_data[-train_index, ]

# Fit the SVM model on the training data
svm_model <- svm(event ~ ., data = train_data, kernel = "linear", scale = TRUE, cost = 10)

# Make predictions on the testing data
predictions <- predict(svm_model, newdata = test_data)

# Evaluate the performance of the model using confusion matrix
confusionMatrix(predictions, test_data$event)
```

## Artificial Neural Networks

In this chapter, we will be exploring Artificial Neural Networks (ANN). ANN is a machine learning algorithm inspired by the biological structure of the human brain. We will explain how ANN works, how to train an ANN model, and how to use it to predict employee turnover.

```{r}

```
