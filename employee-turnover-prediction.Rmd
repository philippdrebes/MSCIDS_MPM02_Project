---
title: "Employee Turnover Prediction"
author: "Albesa Istrefaj, Antonia Durisch, Philipp Drebes"
date: "`r Sys.Date()`"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
library(vtreat)
library(ggcorrplot)
library(readr)
library(ggplot2)
library(gridExtra)
library(mgcv)
```

# MSCIDS MPM02: Employee Turnover Prediction

## Introduction

Welcome to our project on employee turnover prediction! In this project, we will be using various machine learning algorithms to analyze a dataset containing employee turnover data and develop predictive models.

Employee turnover is a critical issue for companies, as it can result in significant costs such as recruitment, training, and lost productivity. Identifying factors that contribute to employee turnover and developing accurate predictive models can help companies better understand employee behavior and improve employee retention.

## Preparation

```{r}
turnover <- read_csv('data/turnover.csv', col_names=TRUE)
summary(turnover)
```

### One-Hot encoding

```{r}
dummy <- dummyVars(" ~ .", data=df)

#perform one-hot encoding on data frame
turnover.oh <- data.frame(predict(dummy, newdata=df))

#summary(turnover.oh)
```

## Linear Models

### Naive Approach

In this chapter, we will be exploring Regression, which is a type of machine learning algorithm used for predicting numerical values. We will explain how regression works, how to train a regression model, and how to use it to predict the likelihood of an employee leaving the company.

```{r}
correlationMatrix <- cor(turnover.oh)
ggcorrplot(correlationMatrix, hc.order = TRUE)

# find attributes that are highly corrected ( > 0.75 )
highlyCorrelated <- findCorrelation(correlationMatrix, cutoff=0.75)
highlyCorrelated <- sort(highlyCorrelated)

# print indexes of highly correlated attributes
print(highlyCorrelated)
names(turnover.oh[highlyCorrelated])

turnover.reduced = turnover.oh[,-c(highlyCorrelated)]

ggcorrplot(cor(turnover.reduced), hc.order = TRUE)
```

```{r}
fit <- lm(event ~ ., data = turnover.reduced)
summary(fit)
```

#### Interpretation

It appears that this model has not a good fit...

### Non-linearities

First we inspect all numerical coefficients for non-linearities.

```{r}

## Age
gg.age <- ggplot(data = turnover, mapping = aes(y = event, x = age)) + 
  geom_point()

plot.age <- gg.age + geom_smooth()

## Extraversion
gg.extraversion <- ggplot(data = turnover, mapping = aes(y = event, x = extraversion)) + 
  geom_point()

plot.extraversion <- gg.extraversion +  geom_smooth()

## Independence
gg.independence <- ggplot(data = turnover, mapping = aes(y = event, x = independ)) + 
  geom_point()

plot.independence <- gg.independence + geom_smooth()

## Self-control
gg.selfcontrol <- ggplot(data = turnover, mapping = aes(y = event, x = selfcontrol)) + 
  geom_point()

plot.selfcontrol <- gg.selfcontrol + geom_smooth()

## Anxiety
gg.anxiety <- ggplot(data = turnover, mapping = aes(y = event, x = anxiety)) + 
  geom_point()

plot.anxiety <- gg.anxiety + geom_smooth()

## Innovator
gg.innovator <- ggplot(data = turnover, mapping = aes(y = event, x = novator)) + 
  geom_point()

plot.innovator <- gg.innovator + geom_smooth()

grid.arrange(plot.age, plot.extraversion, gg.independence, plot.selfcontrol, plot.anxiety, plot.innovator, ncol=2)
```

It appears that only the factor age has a non-linear behavior. We will use a GAM to find its complexity.

```{r}
gam.turnover.1 <- gam(event ~ traffic + way + s(age), 
                   data = turnover, family = binomial)
summary(gam.turnover.1)

plot(gam.turnover.1, residuals = TRUE, select = 1)
```

### Feature Selection

```{r}
# ensure results are repeatable
set.seed(7)
# load the library
library(mlbench)
library(caret)
library(arm)

# prepare training scheme
control <- trainControl(method="repeatedcv", number=10, repeats=3)
# train the model
model <- train(event~., data=turnover.reduced, method="glm", preProcess="scale", trControl=control)
# estimate variable importance
importance <- varImp(model, scale=FALSE)

# summarize importance
print(importance)
# plot importance
plot(importance)

summary(model)
```

### GLM

```{r}
glm.turnover <- glm(event ~ traffic + way + age + profession, 
                   data = turnover, family = binomial)
summary(glm.turnover)

plot(glm.turnover)
```

## Support Vector Machines

In this chapter, we will be exploring the Support Vector Machines (SVM) algorithm. SVM is a powerful algorithm for classification and regression, and is commonly used in machine learning. We will explain how SVM works, how to train an SVM model, and how to use it to predict employee turnover.

```{r}

```

## Artificial Neural Networks

In this chapter, we will be exploring Artificial Neural Networks (ANN). ANN is a machine learning algorithm inspired by the biological structure of the human brain. We will explain how ANN works, how to train an ANN model, and how to use it to predict employee turnover.

```{r}

```
